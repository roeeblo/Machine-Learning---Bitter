# -*- coding: utf-8 -*-
"""bitterProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gL1YBxB3y2bT9K8sySth1oNnn_SwKHPe

#Submitters:

**Oren Ilutowich 318901303**
**Roee Bloch 318846722**

#Start of Project:
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

from google.colab import files

df = pd.read_csv('Bitter.csv')

"""#Understanding the DataFrame for it's preperation
We decided not to display data visualizations at this stage because the dataset is too large, making it difficult to find any meaningful patterns with the human eye.
"""

df.head()

df.shape

df.describe()

df.columns

df.dtypes.unique()

df.isnull().sum().sort_values(ascending=0)

"""#Creating a new copy of the DataFrame excluding features with non-beneficiary data:"""

new_df = df.copy()

new_df['ACTIVITY'].replace(['Bitter', 'Non-Bitter'], [int(1), int(0)], inplace=True)

cols_to_remove = new_df.select_dtypes(include='object').columns
new_df = new_df.drop(columns=cols_to_remove)

print(cols_to_remove, len(cols_to_remove))
print("New Shape: ", new_df.shape)

# Columns that are from type object, to be removed

cols_to_remove = new_df.columns[new_df.apply(lambda col: col.value_counts().max() > len(df) / 2)]

cols_to_remove = cols_to_remove[cols_to_remove != 'ACTIVITY']  # Exclude 'ACTIVITY' column
new_df = new_df.drop(columns=cols_to_remove)

print(cols_to_remove, len(cols_to_remove))
print("New Shape: ", new_df.shape)

# Columns that have more than 50% of values are the same, to be removed

cols_to_remove = new_df.columns[new_df.isnull().mean() > 0.05]
print(cols_to_remove, len(cols_to_remove))

# Columns that have more than 5% of values as null, there are none, but in theory to be removed

new_df.head()

"""##Finding and Removing Features that have high outliers count: (Using IQR)"""

Q1 = new_df.quantile(0.25)
Q3 = new_df.quantile(0.75)
IQR = Q3 - Q1

outliers = ((new_df < Q1 - 1.5 * IQR) | (new_df > Q3 + 1.5 * IQR))
outlier_percentage = outliers.sum() / len(new_df) * 100

# Drop columns with more than 10% outliers
threshold = 10
columns_to_drop = outlier_percentage[outlier_percentage > threshold].index
new_df = new_df.drop(columns=columns_to_drop)

print(columns_to_drop, len(columns_to_drop))
print("New Shape: ", new_df.shape)

"""##Finding and Removing rows with too many outliers from the copy DataFrame:"""

outliers = ((new_df<=(new_df.mean()-3*new_df.std())) | (new_df>=(new_df.mean()+3*new_df.std())))
outliers_count=outliers.sum(axis=1)
outliers_count.sort_values(ascending=0)

outliers_rows_to_drop = new_df.index[outliers_count/len(new_df.columns)>0.2]
new_df = new_df.drop(outliers_rows_to_drop)

print(outliers_rows_to_drop, len(outliers_rows_to_drop))
print("New Shape: ", new_df.shape)

# Removing rows where more than 20% of their data are outliers.

"""##Finding and Removing variables with high correlation from the copy DataFrame: (keeping one)"""

corr_matrix = new_df.corr().abs()
corr_matrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
high_corr_cols = corr_matrix.columns[(corr_matrix.max() > 0.8)].to_list()
new_df = new_df.drop(columns=high_corr_cols)

print(high_corr_cols, len(high_corr_cols))
print("New Shape: ", new_df.shape)

#Removing one of the two variables that have a correlation of more than 0.8 between them.

"""##The new final DataFrame"""

new_df

"""#Presenting the Data Visualization"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=new_df.drop("ACTIVITY", axis=1))
plt.title("Boxplot of Features")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
new_df.drop("ACTIVITY", axis=1).hist(bins=15, figsize=(15, 10))
plt.suptitle("Histograms of Features")
plt.tight_layout()
plt.show()

"""#Theoretical statistics table for all features:

*No binary features left in the dataset
"""

range_values = []
for col in new_df.drop("ACTIVITY", axis=1).columns:
    range_values.append(f'{new_df[col].min()}-{new_df[col].max()}')

mean_values = []
for col in new_df.drop("ACTIVITY", axis=1).columns:
    mean_values.append(new_df[col].mean())

std_values = []
for col in new_df.drop("ACTIVITY", axis=1).columns:
    std_values.append(new_df[col].std())

stats_df = pd.DataFrame({
    "Range": range_values,
    "Mean": mean_values,
    "Std": std_values
}, index=new_df.drop("ACTIVITY", axis=1).columns)

stats_df

"""#Noramlizing the Dataset: (using StandradScaler)"""

scaler = StandardScaler()
normalized_new_df = scaler.fit_transform(new_df.drop("ACTIVITY", axis=1))

normalized_new_df = pd.DataFrame(normalized_new_df, columns=new_df.drop("ACTIVITY", axis=1).columns)

normalized_new_df['ACTIVITY'] = new_df['ACTIVITY']

normalized_new_df